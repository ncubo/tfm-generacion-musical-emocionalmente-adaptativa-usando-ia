[
  {
    "epoch": 0.015600624024960999,
    "grad_norm": 24.38445281982422,
    "learning_rate": 2.8678304239401496e-06,
    "loss": 6.8846,
    "step": 25
  },
  {
    "epoch": 0.031201248049921998,
    "grad_norm": 17.223806381225586,
    "learning_rate": 5.98503740648379e-06,
    "loss": 5.3306,
    "step": 50
  },
  {
    "epoch": 0.046801872074883,
    "grad_norm": 6.729082107543945,
    "learning_rate": 9.102244389027433e-06,
    "loss": 4.7699,
    "step": 75
  },
  {
    "epoch": 0.062402496099843996,
    "grad_norm": 7.174221515655518,
    "learning_rate": 1.2219451371571072e-05,
    "loss": 4.3394,
    "step": 100
  },
  {
    "epoch": 0.078003120124805,
    "grad_norm": 8.289056777954102,
    "learning_rate": 1.5336658354114714e-05,
    "loss": 4.0619,
    "step": 125
  },
  {
    "epoch": 0.093603744149766,
    "grad_norm": 6.382279872894287,
    "learning_rate": 1.8453865336658355e-05,
    "loss": 4.1098,
    "step": 150
  },
  {
    "epoch": 0.10920436817472699,
    "grad_norm": 11.54468822479248,
    "learning_rate": 2.1571072319201995e-05,
    "loss": 3.9632,
    "step": 175
  },
  {
    "epoch": 0.12480499219968799,
    "grad_norm": 6.772420406341553,
    "learning_rate": 2.4688279301745636e-05,
    "loss": 3.7175,
    "step": 200
  },
  {
    "epoch": 0.14040561622464898,
    "grad_norm": 7.248327255249023,
    "learning_rate": 2.7805486284289277e-05,
    "loss": 3.7119,
    "step": 225
  },
  {
    "epoch": 0.15600624024961,
    "grad_norm": 8.45323657989502,
    "learning_rate": 3.092269326683292e-05,
    "loss": 3.5867,
    "step": 250
  },
  {
    "epoch": 0.17160686427457097,
    "grad_norm": 9.15925121307373,
    "learning_rate": 3.403990024937656e-05,
    "loss": 3.4274,
    "step": 275
  },
  {
    "epoch": 0.187207488299532,
    "grad_norm": 8.826190948486328,
    "learning_rate": 3.71571072319202e-05,
    "loss": 3.2619,
    "step": 300
  },
  {
    "epoch": 0.20280811232449297,
    "grad_norm": 7.933079242706299,
    "learning_rate": 4.027431421446384e-05,
    "loss": 3.3095,
    "step": 325
  },
  {
    "epoch": 0.21840873634945399,
    "grad_norm": 8.371842384338379,
    "learning_rate": 4.339152119700749e-05,
    "loss": 3.1599,
    "step": 350
  },
  {
    "epoch": 0.23400936037441497,
    "grad_norm": 6.47997522354126,
    "learning_rate": 4.6508728179551124e-05,
    "loss": 3.294,
    "step": 375
  },
  {
    "epoch": 0.24960998439937598,
    "grad_norm": 6.735440731048584,
    "learning_rate": 4.962593516209477e-05,
    "loss": 2.9889,
    "step": 400
  },
  {
    "epoch": 0.26521060842433697,
    "grad_norm": 7.22305965423584,
    "learning_rate": 4.98555292881534e-05,
    "loss": 3.2354,
    "step": 425
  },
  {
    "epoch": 0.28081123244929795,
    "grad_norm": 6.558766841888428,
    "learning_rate": 4.969135802469136e-05,
    "loss": 3.1078,
    "step": 450
  },
  {
    "epoch": 0.296411856474259,
    "grad_norm": 5.322831630706787,
    "learning_rate": 4.9527186761229313e-05,
    "loss": 3.0641,
    "step": 475
  },
  {
    "epoch": 0.31201248049922,
    "grad_norm": 6.1418776512146,
    "learning_rate": 4.9363015497767276e-05,
    "loss": 3.019,
    "step": 500
  },
  {
    "epoch": 0.31201248049922,
    "eval_loss": 2.83036470413208,
    "eval_runtime": 30.5148,
    "eval_samples_per_second": 45.748,
    "eval_steps_per_second": 11.437,
    "step": 500
  },
  {
    "epoch": 0.32761310452418096,
    "grad_norm": 4.715332508087158,
    "learning_rate": 4.919884423430523e-05,
    "loss": 2.8203,
    "step": 525
  },
  {
    "epoch": 0.34321372854914195,
    "grad_norm": 3.9816601276397705,
    "learning_rate": 4.903467297084319e-05,
    "loss": 2.8957,
    "step": 550
  },
  {
    "epoch": 0.358814352574103,
    "grad_norm": 4.457176685333252,
    "learning_rate": 4.887050170738114e-05,
    "loss": 2.809,
    "step": 575
  },
  {
    "epoch": 0.374414976599064,
    "grad_norm": 5.05253791809082,
    "learning_rate": 4.87063304439191e-05,
    "loss": 2.8119,
    "step": 600
  },
  {
    "epoch": 0.39001560062402496,
    "grad_norm": 6.4057936668396,
    "learning_rate": 4.8542159180457054e-05,
    "loss": 2.8113,
    "step": 625
  },
  {
    "epoch": 0.40561622464898595,
    "grad_norm": 6.34409236907959,
    "learning_rate": 4.837798791699501e-05,
    "loss": 2.8491,
    "step": 650
  },
  {
    "epoch": 0.42121684867394693,
    "grad_norm": 4.957258701324463,
    "learning_rate": 4.8213816653532966e-05,
    "loss": 2.7341,
    "step": 675
  },
  {
    "epoch": 0.43681747269890797,
    "grad_norm": 4.790589809417725,
    "learning_rate": 4.804964539007092e-05,
    "loss": 2.7293,
    "step": 700
  },
  {
    "epoch": 0.45241809672386896,
    "grad_norm": 4.8145833015441895,
    "learning_rate": 4.7885474126608884e-05,
    "loss": 2.6687,
    "step": 725
  },
  {
    "epoch": 0.46801872074882994,
    "grad_norm": 5.240959167480469,
    "learning_rate": 4.772130286314684e-05,
    "loss": 2.8123,
    "step": 750
  },
  {
    "epoch": 0.4836193447737909,
    "grad_norm": 4.258289337158203,
    "learning_rate": 4.7557131599684796e-05,
    "loss": 2.5995,
    "step": 775
  },
  {
    "epoch": 0.49921996879875197,
    "grad_norm": 6.437411785125732,
    "learning_rate": 4.739296033622275e-05,
    "loss": 2.6815,
    "step": 800
  },
  {
    "epoch": 0.514820592823713,
    "grad_norm": 4.413693904876709,
    "learning_rate": 4.722878907276071e-05,
    "loss": 2.4823,
    "step": 825
  },
  {
    "epoch": 0.5304212168486739,
    "grad_norm": 4.03924036026001,
    "learning_rate": 4.706461780929866e-05,
    "loss": 2.5816,
    "step": 850
  },
  {
    "epoch": 0.5460218408736349,
    "grad_norm": 4.081823825836182,
    "learning_rate": 4.690044654583662e-05,
    "loss": 2.7853,
    "step": 875
  },
  {
    "epoch": 0.5616224648985959,
    "grad_norm": 5.32093620300293,
    "learning_rate": 4.6736275282374574e-05,
    "loss": 2.6745,
    "step": 900
  },
  {
    "epoch": 0.5772230889235569,
    "grad_norm": 4.051243782043457,
    "learning_rate": 4.657210401891253e-05,
    "loss": 2.6078,
    "step": 925
  },
  {
    "epoch": 0.592823712948518,
    "grad_norm": 3.4821555614471436,
    "learning_rate": 4.640793275545049e-05,
    "loss": 2.5492,
    "step": 950
  },
  {
    "epoch": 0.608424336973479,
    "grad_norm": 4.192740440368652,
    "learning_rate": 4.624376149198845e-05,
    "loss": 2.4451,
    "step": 975
  },
  {
    "epoch": 0.62402496099844,
    "grad_norm": 5.14747428894043,
    "learning_rate": 4.6079590228526404e-05,
    "loss": 2.4953,
    "step": 1000
  },
  {
    "epoch": 0.62402496099844,
    "eval_loss": 2.5135817527770996,
    "eval_runtime": 30.4943,
    "eval_samples_per_second": 45.779,
    "eval_steps_per_second": 11.445,
    "step": 1000
  },
  {
    "epoch": 0.6396255850234009,
    "grad_norm": 4.295966148376465,
    "learning_rate": 4.591541896506435e-05,
    "loss": 2.6016,
    "step": 1025
  },
  {
    "epoch": 0.6552262090483619,
    "grad_norm": 3.3974833488464355,
    "learning_rate": 4.5751247701602315e-05,
    "loss": 2.5432,
    "step": 1050
  },
  {
    "epoch": 0.6708268330733229,
    "grad_norm": 3.7340798377990723,
    "learning_rate": 4.558707643814027e-05,
    "loss": 2.5834,
    "step": 1075
  },
  {
    "epoch": 0.6864274570982839,
    "grad_norm": 3.308516263961792,
    "learning_rate": 4.5422905174678226e-05,
    "loss": 2.6062,
    "step": 1100
  },
  {
    "epoch": 0.7020280811232449,
    "grad_norm": 3.742551565170288,
    "learning_rate": 4.525873391121618e-05,
    "loss": 2.5532,
    "step": 1125
  },
  {
    "epoch": 0.717628705148206,
    "grad_norm": 3.8243179321289062,
    "learning_rate": 4.509456264775414e-05,
    "loss": 2.4352,
    "step": 1150
  },
  {
    "epoch": 0.733229329173167,
    "grad_norm": 3.658060312271118,
    "learning_rate": 4.49303913842921e-05,
    "loss": 2.4964,
    "step": 1175
  },
  {
    "epoch": 0.748829953198128,
    "grad_norm": 5.533486366271973,
    "learning_rate": 4.4766220120830056e-05,
    "loss": 2.5295,
    "step": 1200
  },
  {
    "epoch": 0.7644305772230889,
    "grad_norm": 3.807722806930542,
    "learning_rate": 4.4602048857368005e-05,
    "loss": 2.3574,
    "step": 1225
  },
  {
    "epoch": 0.7800312012480499,
    "grad_norm": 4.275067329406738,
    "learning_rate": 4.443787759390596e-05,
    "loss": 2.4279,
    "step": 1250
  },
  {
    "epoch": 0.7956318252730109,
    "grad_norm": 4.450705528259277,
    "learning_rate": 4.427370633044392e-05,
    "loss": 2.3983,
    "step": 1275
  },
  {
    "epoch": 0.8112324492979719,
    "grad_norm": 3.5745980739593506,
    "learning_rate": 4.410953506698188e-05,
    "loss": 2.4703,
    "step": 1300
  },
  {
    "epoch": 0.8268330733229329,
    "grad_norm": 3.3975579738616943,
    "learning_rate": 4.3945363803519835e-05,
    "loss": 2.3512,
    "step": 1325
  },
  {
    "epoch": 0.8424336973478939,
    "grad_norm": 3.973829507827759,
    "learning_rate": 4.378119254005779e-05,
    "loss": 2.4434,
    "step": 1350
  },
  {
    "epoch": 0.858034321372855,
    "grad_norm": 4.125984191894531,
    "learning_rate": 4.3617021276595746e-05,
    "loss": 2.3813,
    "step": 1375
  },
  {
    "epoch": 0.8736349453978159,
    "grad_norm": 3.828778028488159,
    "learning_rate": 4.345285001313371e-05,
    "loss": 2.3118,
    "step": 1400
  },
  {
    "epoch": 0.8892355694227769,
    "grad_norm": 4.00213098526001,
    "learning_rate": 4.328867874967166e-05,
    "loss": 2.2946,
    "step": 1425
  },
  {
    "epoch": 0.9048361934477379,
    "grad_norm": 3.9917988777160645,
    "learning_rate": 4.312450748620961e-05,
    "loss": 2.3215,
    "step": 1450
  },
  {
    "epoch": 0.9204368174726989,
    "grad_norm": 3.6003029346466064,
    "learning_rate": 4.296033622274757e-05,
    "loss": 2.3959,
    "step": 1475
  },
  {
    "epoch": 0.9360374414976599,
    "grad_norm": 3.269263744354248,
    "learning_rate": 4.279616495928553e-05,
    "loss": 2.4317,
    "step": 1500
  },
  {
    "epoch": 0.9360374414976599,
    "eval_loss": 2.3716208934783936,
    "eval_runtime": 30.5359,
    "eval_samples_per_second": 45.717,
    "eval_steps_per_second": 11.429,
    "step": 1500
  },
  {
    "epoch": 0.9516380655226209,
    "grad_norm": 4.276914119720459,
    "learning_rate": 4.263199369582349e-05,
    "loss": 2.3125,
    "step": 1525
  },
  {
    "epoch": 0.9672386895475819,
    "grad_norm": 3.0814099311828613,
    "learning_rate": 4.246782243236144e-05,
    "loss": 2.3798,
    "step": 1550
  },
  {
    "epoch": 0.982839313572543,
    "grad_norm": 3.2269248962402344,
    "learning_rate": 4.23036511688994e-05,
    "loss": 2.4678,
    "step": 1575
  },
  {
    "epoch": 0.9984399375975039,
    "grad_norm": 3.051676034927368,
    "learning_rate": 4.2139479905437354e-05,
    "loss": 2.326,
    "step": 1600
  },
  {
    "epoch": 1.0137285491419656,
    "grad_norm": 2.9882922172546387,
    "learning_rate": 4.197530864197531e-05,
    "loss": 2.3532,
    "step": 1625
  },
  {
    "epoch": 1.0293291731669267,
    "grad_norm": 4.1942901611328125,
    "learning_rate": 4.1811137378513266e-05,
    "loss": 2.352,
    "step": 1650
  },
  {
    "epoch": 1.0449297971918876,
    "grad_norm": 3.559877395629883,
    "learning_rate": 4.164696611505122e-05,
    "loss": 2.2733,
    "step": 1675
  },
  {
    "epoch": 1.0605304212168487,
    "grad_norm": 4.959405422210693,
    "learning_rate": 4.148279485158918e-05,
    "loss": 2.1562,
    "step": 1700
  },
  {
    "epoch": 1.0761310452418096,
    "grad_norm": 3.805197238922119,
    "learning_rate": 4.131862358812714e-05,
    "loss": 2.2391,
    "step": 1725
  },
  {
    "epoch": 1.0917316692667707,
    "grad_norm": 3.234485149383545,
    "learning_rate": 4.1154452324665095e-05,
    "loss": 2.1552,
    "step": 1750
  },
  {
    "epoch": 1.1073322932917318,
    "grad_norm": 3.547656297683716,
    "learning_rate": 4.099028106120305e-05,
    "loss": 2.2725,
    "step": 1775
  },
  {
    "epoch": 1.1229329173166926,
    "grad_norm": 6.532036781311035,
    "learning_rate": 4.082610979774101e-05,
    "loss": 2.2173,
    "step": 1800
  },
  {
    "epoch": 1.1385335413416537,
    "grad_norm": 3.4568724632263184,
    "learning_rate": 4.066193853427896e-05,
    "loss": 2.1227,
    "step": 1825
  },
  {
    "epoch": 1.1541341653666146,
    "grad_norm": 4.547468662261963,
    "learning_rate": 4.049776727081692e-05,
    "loss": 2.1835,
    "step": 1850
  },
  {
    "epoch": 1.1697347893915757,
    "grad_norm": 3.200404167175293,
    "learning_rate": 4.0333596007354874e-05,
    "loss": 2.4898,
    "step": 1875
  },
  {
    "epoch": 1.1853354134165366,
    "grad_norm": 3.8066463470458984,
    "learning_rate": 4.016942474389283e-05,
    "loss": 2.1753,
    "step": 1900
  },
  {
    "epoch": 1.2009360374414977,
    "grad_norm": 3.47411847114563,
    "learning_rate": 4.0005253480430785e-05,
    "loss": 2.2375,
    "step": 1925
  },
  {
    "epoch": 1.2165366614664586,
    "grad_norm": 3.5632483959198,
    "learning_rate": 3.984108221696875e-05,
    "loss": 2.3693,
    "step": 1950
  },
  {
    "epoch": 1.2321372854914197,
    "grad_norm": 3.403367757797241,
    "learning_rate": 3.96769109535067e-05,
    "loss": 2.0968,
    "step": 1975
  },
  {
    "epoch": 1.2477379095163807,
    "grad_norm": 2.9700474739074707,
    "learning_rate": 3.951273969004466e-05,
    "loss": 2.3206,
    "step": 2000
  },
  {
    "epoch": 1.2477379095163807,
    "eval_loss": 2.2793850898742676,
    "eval_runtime": 30.4819,
    "eval_samples_per_second": 45.798,
    "eval_steps_per_second": 11.449,
    "step": 2000
  },
  {
    "epoch": 1.2633385335413416,
    "grad_norm": 4.293006420135498,
    "learning_rate": 3.934856842658261e-05,
    "loss": 2.1424,
    "step": 2025
  },
  {
    "epoch": 1.2789391575663027,
    "grad_norm": 3.205230712890625,
    "learning_rate": 3.918439716312057e-05,
    "loss": 2.2849,
    "step": 2050
  },
  {
    "epoch": 1.2945397815912636,
    "grad_norm": 2.766178607940674,
    "learning_rate": 3.9020225899658526e-05,
    "loss": 2.1943,
    "step": 2075
  },
  {
    "epoch": 1.3101404056162247,
    "grad_norm": 3.4002981185913086,
    "learning_rate": 3.885605463619648e-05,
    "loss": 2.203,
    "step": 2100
  },
  {
    "epoch": 1.3257410296411856,
    "grad_norm": 2.788382053375244,
    "learning_rate": 3.869188337273444e-05,
    "loss": 2.2429,
    "step": 2125
  },
  {
    "epoch": 1.3413416536661467,
    "grad_norm": 3.771798610687256,
    "learning_rate": 3.852771210927239e-05,
    "loss": 2.2666,
    "step": 2150
  },
  {
    "epoch": 1.3569422776911075,
    "grad_norm": 4.380069255828857,
    "learning_rate": 3.8363540845810356e-05,
    "loss": 2.2049,
    "step": 2175
  },
  {
    "epoch": 1.3725429017160686,
    "grad_norm": 3.6116766929626465,
    "learning_rate": 3.819936958234831e-05,
    "loss": 2.1377,
    "step": 2200
  },
  {
    "epoch": 1.3881435257410297,
    "grad_norm": 2.7738049030303955,
    "learning_rate": 3.803519831888626e-05,
    "loss": 2.1606,
    "step": 2225
  },
  {
    "epoch": 1.4037441497659906,
    "grad_norm": 2.983342409133911,
    "learning_rate": 3.7871027055424216e-05,
    "loss": 2.2137,
    "step": 2250
  },
  {
    "epoch": 1.4193447737909517,
    "grad_norm": 4.2264604568481445,
    "learning_rate": 3.770685579196218e-05,
    "loss": 2.2497,
    "step": 2275
  },
  {
    "epoch": 1.4349453978159126,
    "grad_norm": 3.414374589920044,
    "learning_rate": 3.7542684528500134e-05,
    "loss": 2.1567,
    "step": 2300
  },
  {
    "epoch": 1.4505460218408737,
    "grad_norm": 3.582930326461792,
    "learning_rate": 3.737851326503809e-05,
    "loss": 2.1735,
    "step": 2325
  },
  {
    "epoch": 1.4661466458658348,
    "grad_norm": 2.7239813804626465,
    "learning_rate": 3.7214342001576046e-05,
    "loss": 2.0606,
    "step": 2350
  },
  {
    "epoch": 1.4817472698907956,
    "grad_norm": 2.696765422821045,
    "learning_rate": 3.7050170738114e-05,
    "loss": 2.2092,
    "step": 2375
  },
  {
    "epoch": 1.4973478939157565,
    "grad_norm": 3.1724917888641357,
    "learning_rate": 3.6885999474651964e-05,
    "loss": 2.1075,
    "step": 2400
  },
  {
    "epoch": 1.5129485179407176,
    "grad_norm": 3.7230143547058105,
    "learning_rate": 3.672182821118991e-05,
    "loss": 2.1127,
    "step": 2425
  },
  {
    "epoch": 1.5285491419656787,
    "grad_norm": 3.187260150909424,
    "learning_rate": 3.655765694772787e-05,
    "loss": 2.1978,
    "step": 2450
  },
  {
    "epoch": 1.5441497659906396,
    "grad_norm": 3.3993020057678223,
    "learning_rate": 3.6393485684265824e-05,
    "loss": 2.1126,
    "step": 2475
  },
  {
    "epoch": 1.5597503900156007,
    "grad_norm": 3.0010578632354736,
    "learning_rate": 3.622931442080379e-05,
    "loss": 2.1116,
    "step": 2500
  },
  {
    "epoch": 1.5597503900156007,
    "eval_loss": 2.217423677444458,
    "eval_runtime": 30.4932,
    "eval_samples_per_second": 45.781,
    "eval_steps_per_second": 11.445,
    "step": 2500
  },
  {
    "epoch": 1.5753510140405615,
    "grad_norm": 3.442070484161377,
    "learning_rate": 3.606514315734174e-05,
    "loss": 2.1269,
    "step": 2525
  },
  {
    "epoch": 1.5909516380655226,
    "grad_norm": 2.577725410461426,
    "learning_rate": 3.59009718938797e-05,
    "loss": 2.2765,
    "step": 2550
  },
  {
    "epoch": 1.6065522620904837,
    "grad_norm": 3.4136860370635986,
    "learning_rate": 3.5736800630417654e-05,
    "loss": 2.0796,
    "step": 2575
  },
  {
    "epoch": 1.6221528861154446,
    "grad_norm": 3.536093235015869,
    "learning_rate": 3.557262936695561e-05,
    "loss": 2.1829,
    "step": 2600
  },
  {
    "epoch": 1.6377535101404055,
    "grad_norm": 3.072450637817383,
    "learning_rate": 3.5408458103493565e-05,
    "loss": 2.1869,
    "step": 2625
  },
  {
    "epoch": 1.6533541341653666,
    "grad_norm": 3.155167579650879,
    "learning_rate": 3.524428684003152e-05,
    "loss": 2.1671,
    "step": 2650
  },
  {
    "epoch": 1.6689547581903277,
    "grad_norm": 2.4254250526428223,
    "learning_rate": 3.508011557656948e-05,
    "loss": 2.1054,
    "step": 2675
  },
  {
    "epoch": 1.6845553822152888,
    "grad_norm": 2.8526346683502197,
    "learning_rate": 3.491594431310743e-05,
    "loss": 2.0938,
    "step": 2700
  },
  {
    "epoch": 1.7001560062402497,
    "grad_norm": 2.6860721111297607,
    "learning_rate": 3.4751773049645395e-05,
    "loss": 2.0977,
    "step": 2725
  },
  {
    "epoch": 1.7157566302652105,
    "grad_norm": 2.774052619934082,
    "learning_rate": 3.458760178618335e-05,
    "loss": 1.9668,
    "step": 2750
  },
  {
    "epoch": 1.7313572542901716,
    "grad_norm": 2.6345736980438232,
    "learning_rate": 3.4423430522721306e-05,
    "loss": 2.2088,
    "step": 2775
  },
  {
    "epoch": 1.7469578783151327,
    "grad_norm": 3.165001153945923,
    "learning_rate": 3.425925925925926e-05,
    "loss": 2.0484,
    "step": 2800
  },
  {
    "epoch": 1.7625585023400936,
    "grad_norm": 2.6778006553649902,
    "learning_rate": 3.409508799579722e-05,
    "loss": 2.0495,
    "step": 2825
  },
  {
    "epoch": 1.7781591263650545,
    "grad_norm": 2.5897293090820312,
    "learning_rate": 3.3930916732335173e-05,
    "loss": 2.0405,
    "step": 2850
  },
  {
    "epoch": 1.7937597503900156,
    "grad_norm": 2.8741893768310547,
    "learning_rate": 3.376674546887313e-05,
    "loss": 2.161,
    "step": 2875
  },
  {
    "epoch": 1.8093603744149767,
    "grad_norm": 5.358283519744873,
    "learning_rate": 3.3602574205411085e-05,
    "loss": 2.0639,
    "step": 2900
  },
  {
    "epoch": 1.8249609984399378,
    "grad_norm": 2.8043594360351562,
    "learning_rate": 3.343840294194904e-05,
    "loss": 2.1135,
    "step": 2925
  },
  {
    "epoch": 1.8405616224648986,
    "grad_norm": 3.2490930557250977,
    "learning_rate": 3.3274231678487e-05,
    "loss": 2.0223,
    "step": 2950
  },
  {
    "epoch": 1.8561622464898595,
    "grad_norm": 2.8066201210021973,
    "learning_rate": 3.311006041502496e-05,
    "loss": 2.0879,
    "step": 2975
  },
  {
    "epoch": 1.8717628705148206,
    "grad_norm": 3.2775681018829346,
    "learning_rate": 3.2945889151562914e-05,
    "loss": 2.0163,
    "step": 3000
  },
  {
    "epoch": 1.8717628705148206,
    "eval_loss": 2.1404964923858643,
    "eval_runtime": 30.4455,
    "eval_samples_per_second": 45.852,
    "eval_steps_per_second": 11.463,
    "step": 3000
  },
  {
    "epoch": 1.8873634945397817,
    "grad_norm": 2.4815688133239746,
    "learning_rate": 3.2781717888100863e-05,
    "loss": 2.2128,
    "step": 3025
  },
  {
    "epoch": 1.9029641185647426,
    "grad_norm": 2.620225191116333,
    "learning_rate": 3.2617546624638826e-05,
    "loss": 2.1449,
    "step": 3050
  },
  {
    "epoch": 1.9185647425897034,
    "grad_norm": 3.22074556350708,
    "learning_rate": 3.245337536117678e-05,
    "loss": 2.0162,
    "step": 3075
  },
  {
    "epoch": 1.9341653666146645,
    "grad_norm": 3.8594515323638916,
    "learning_rate": 3.228920409771474e-05,
    "loss": 1.9696,
    "step": 3100
  },
  {
    "epoch": 1.9497659906396256,
    "grad_norm": 2.5882835388183594,
    "learning_rate": 3.212503283425269e-05,
    "loss": 2.1517,
    "step": 3125
  },
  {
    "epoch": 1.9653666146645867,
    "grad_norm": 2.944230079650879,
    "learning_rate": 3.196086157079065e-05,
    "loss": 2.1842,
    "step": 3150
  },
  {
    "epoch": 1.9809672386895476,
    "grad_norm": 3.745962142944336,
    "learning_rate": 3.179669030732861e-05,
    "loss": 2.1642,
    "step": 3175
  },
  {
    "epoch": 1.9965678627145085,
    "grad_norm": 2.8810176849365234,
    "learning_rate": 3.163251904386657e-05,
    "loss": 2.0082,
    "step": 3200
  },
  {
    "epoch": 2.01185647425897,
    "grad_norm": 2.8491735458374023,
    "learning_rate": 3.1468347780404516e-05,
    "loss": 2.0161,
    "step": 3225
  },
  {
    "epoch": 2.0274570982839313,
    "grad_norm": 2.9741873741149902,
    "learning_rate": 3.130417651694247e-05,
    "loss": 2.0037,
    "step": 3250
  },
  {
    "epoch": 2.0430577223088924,
    "grad_norm": 3.7303314208984375,
    "learning_rate": 3.1140005253480434e-05,
    "loss": 2.0319,
    "step": 3275
  },
  {
    "epoch": 2.0586583463338535,
    "grad_norm": 3.107811689376831,
    "learning_rate": 3.097583399001839e-05,
    "loss": 1.9964,
    "step": 3300
  },
  {
    "epoch": 2.074258970358814,
    "grad_norm": 2.35685396194458,
    "learning_rate": 3.0811662726556345e-05,
    "loss": 2.0329,
    "step": 3325
  },
  {
    "epoch": 2.089859594383775,
    "grad_norm": 3.552837610244751,
    "learning_rate": 3.06474914630943e-05,
    "loss": 2.0087,
    "step": 3350
  },
  {
    "epoch": 2.1054602184087363,
    "grad_norm": 3.0538549423217773,
    "learning_rate": 3.048332019963226e-05,
    "loss": 1.972,
    "step": 3375
  },
  {
    "epoch": 2.1210608424336974,
    "grad_norm": 3.4732165336608887,
    "learning_rate": 3.0319148936170216e-05,
    "loss": 1.9707,
    "step": 3400
  },
  {
    "epoch": 2.1366614664586585,
    "grad_norm": 2.7721288204193115,
    "learning_rate": 3.0154977672708168e-05,
    "loss": 1.9814,
    "step": 3425
  },
  {
    "epoch": 2.152262090483619,
    "grad_norm": 3.438993453979492,
    "learning_rate": 2.9990806409246124e-05,
    "loss": 2.1151,
    "step": 3450
  },
  {
    "epoch": 2.1678627145085803,
    "grad_norm": 3.3520195484161377,
    "learning_rate": 2.9826635145784083e-05,
    "loss": 1.8319,
    "step": 3475
  },
  {
    "epoch": 2.1834633385335414,
    "grad_norm": 2.775683641433716,
    "learning_rate": 2.966246388232204e-05,
    "loss": 1.9366,
    "step": 3500
  },
  {
    "epoch": 2.1834633385335414,
    "eval_loss": 2.102313280105591,
    "eval_runtime": 30.5364,
    "eval_samples_per_second": 45.716,
    "eval_steps_per_second": 11.429,
    "step": 3500
  },
  {
    "epoch": 2.1990639625585024,
    "grad_norm": 2.901067018508911,
    "learning_rate": 2.9498292618859994e-05,
    "loss": 1.957,
    "step": 3525
  },
  {
    "epoch": 2.2146645865834635,
    "grad_norm": 2.618426561355591,
    "learning_rate": 2.9334121355397954e-05,
    "loss": 2.0551,
    "step": 3550
  },
  {
    "epoch": 2.230265210608424,
    "grad_norm": 3.0349318981170654,
    "learning_rate": 2.916995009193591e-05,
    "loss": 1.8771,
    "step": 3575
  },
  {
    "epoch": 2.2458658346333853,
    "grad_norm": 2.706347703933716,
    "learning_rate": 2.900577882847387e-05,
    "loss": 2.0416,
    "step": 3600
  },
  {
    "epoch": 2.2614664586583464,
    "grad_norm": 2.8332631587982178,
    "learning_rate": 2.8841607565011824e-05,
    "loss": 1.8687,
    "step": 3625
  },
  {
    "epoch": 2.2770670826833075,
    "grad_norm": 2.7566821575164795,
    "learning_rate": 2.8677436301549776e-05,
    "loss": 2.0418,
    "step": 3650
  },
  {
    "epoch": 2.292667706708268,
    "grad_norm": 2.8981525897979736,
    "learning_rate": 2.8513265038087732e-05,
    "loss": 1.9927,
    "step": 3675
  },
  {
    "epoch": 2.3082683307332292,
    "grad_norm": 3.4771502017974854,
    "learning_rate": 2.834909377462569e-05,
    "loss": 1.9519,
    "step": 3700
  },
  {
    "epoch": 2.3238689547581903,
    "grad_norm": 2.8493032455444336,
    "learning_rate": 2.8184922511163647e-05,
    "loss": 1.9949,
    "step": 3725
  },
  {
    "epoch": 2.3394695787831514,
    "grad_norm": 2.7158405780792236,
    "learning_rate": 2.8020751247701603e-05,
    "loss": 1.9194,
    "step": 3750
  },
  {
    "epoch": 2.355070202808112,
    "grad_norm": 3.217482805252075,
    "learning_rate": 2.7856579984239562e-05,
    "loss": 2.01,
    "step": 3775
  },
  {
    "epoch": 2.370670826833073,
    "grad_norm": 2.7477517127990723,
    "learning_rate": 2.7692408720777517e-05,
    "loss": 1.9202,
    "step": 3800
  },
  {
    "epoch": 2.3862714508580343,
    "grad_norm": 3.6451992988586426,
    "learning_rate": 2.7528237457315477e-05,
    "loss": 1.937,
    "step": 3825
  },
  {
    "epoch": 2.4018720748829954,
    "grad_norm": 3.1458168029785156,
    "learning_rate": 2.7364066193853425e-05,
    "loss": 2.0725,
    "step": 3850
  },
  {
    "epoch": 2.4174726989079565,
    "grad_norm": 2.727280378341675,
    "learning_rate": 2.7199894930391385e-05,
    "loss": 1.9101,
    "step": 3875
  },
  {
    "epoch": 2.433073322932917,
    "grad_norm": 2.836583137512207,
    "learning_rate": 2.703572366692934e-05,
    "loss": 2.0568,
    "step": 3900
  },
  {
    "epoch": 2.448673946957878,
    "grad_norm": 2.993069648742676,
    "learning_rate": 2.68715524034673e-05,
    "loss": 1.939,
    "step": 3925
  },
  {
    "epoch": 2.4642745709828393,
    "grad_norm": 2.7826945781707764,
    "learning_rate": 2.6707381140005255e-05,
    "loss": 2.0633,
    "step": 3950
  },
  {
    "epoch": 2.4798751950078004,
    "grad_norm": 2.5848841667175293,
    "learning_rate": 2.654320987654321e-05,
    "loss": 1.8627,
    "step": 3975
  },
  {
    "epoch": 2.4954758190327615,
    "grad_norm": 2.6190121173858643,
    "learning_rate": 2.637903861308117e-05,
    "loss": 1.8562,
    "step": 4000
  },
  {
    "epoch": 2.4954758190327615,
    "eval_loss": 2.0667433738708496,
    "eval_runtime": 30.4424,
    "eval_samples_per_second": 45.857,
    "eval_steps_per_second": 11.464,
    "step": 4000
  },
  {
    "epoch": 2.511076443057722,
    "grad_norm": 3.305210828781128,
    "learning_rate": 2.6214867349619126e-05,
    "loss": 1.8534,
    "step": 4025
  },
  {
    "epoch": 2.5266770670826832,
    "grad_norm": 3.191298484802246,
    "learning_rate": 2.6050696086157078e-05,
    "loss": 1.7634,
    "step": 4050
  },
  {
    "epoch": 2.5422776911076443,
    "grad_norm": 3.35298752784729,
    "learning_rate": 2.5886524822695034e-05,
    "loss": 2.0009,
    "step": 4075
  },
  {
    "epoch": 2.5578783151326054,
    "grad_norm": 3.201030731201172,
    "learning_rate": 2.5722353559232993e-05,
    "loss": 1.927,
    "step": 4100
  },
  {
    "epoch": 2.5734789391575665,
    "grad_norm": 2.717865228652954,
    "learning_rate": 2.555818229577095e-05,
    "loss": 2.0587,
    "step": 4125
  },
  {
    "epoch": 2.589079563182527,
    "grad_norm": 2.8909571170806885,
    "learning_rate": 2.5394011032308908e-05,
    "loss": 1.8616,
    "step": 4150
  },
  {
    "epoch": 2.6046801872074883,
    "grad_norm": 2.6396372318267822,
    "learning_rate": 2.5229839768846863e-05,
    "loss": 1.9048,
    "step": 4175
  },
  {
    "epoch": 2.6202808112324494,
    "grad_norm": 2.157266855239868,
    "learning_rate": 2.506566850538482e-05,
    "loss": 1.9235,
    "step": 4200
  },
  {
    "epoch": 2.63588143525741,
    "grad_norm": 2.6021580696105957,
    "learning_rate": 2.4901497241922775e-05,
    "loss": 1.8732,
    "step": 4225
  },
  {
    "epoch": 2.651482059282371,
    "grad_norm": 2.392674446105957,
    "learning_rate": 2.473732597846073e-05,
    "loss": 1.7906,
    "step": 4250
  },
  {
    "epoch": 2.6670826833073322,
    "grad_norm": 2.8442063331604004,
    "learning_rate": 2.457315471499869e-05,
    "loss": 1.9221,
    "step": 4275
  },
  {
    "epoch": 2.6826833073322933,
    "grad_norm": 2.916346311569214,
    "learning_rate": 2.4408983451536642e-05,
    "loss": 1.9351,
    "step": 4300
  },
  {
    "epoch": 2.6982839313572544,
    "grad_norm": 2.8190016746520996,
    "learning_rate": 2.42448121880746e-05,
    "loss": 1.9303,
    "step": 4325
  },
  {
    "epoch": 2.713884555382215,
    "grad_norm": 2.0852320194244385,
    "learning_rate": 2.4080640924612557e-05,
    "loss": 1.8883,
    "step": 4350
  },
  {
    "epoch": 2.729485179407176,
    "grad_norm": 3.337420701980591,
    "learning_rate": 2.3916469661150516e-05,
    "loss": 1.8496,
    "step": 4375
  },
  {
    "epoch": 2.7450858034321373,
    "grad_norm": 2.698780059814453,
    "learning_rate": 2.3752298397688468e-05,
    "loss": 1.9439,
    "step": 4400
  },
  {
    "epoch": 2.7606864274570984,
    "grad_norm": 2.8120105266571045,
    "learning_rate": 2.3588127134226427e-05,
    "loss": 1.9451,
    "step": 4425
  },
  {
    "epoch": 2.7762870514820595,
    "grad_norm": 2.8963518142700195,
    "learning_rate": 2.3423955870764383e-05,
    "loss": 1.9492,
    "step": 4450
  },
  {
    "epoch": 2.79188767550702,
    "grad_norm": 2.7402000427246094,
    "learning_rate": 2.325978460730234e-05,
    "loss": 1.9087,
    "step": 4475
  },
  {
    "epoch": 2.807488299531981,
    "grad_norm": 2.776564836502075,
    "learning_rate": 2.3095613343840294e-05,
    "loss": 1.8658,
    "step": 4500
  },
  {
    "epoch": 2.807488299531981,
    "eval_loss": 2.03997802734375,
    "eval_runtime": 30.3584,
    "eval_samples_per_second": 45.984,
    "eval_steps_per_second": 11.496,
    "step": 4500
  },
  {
    "epoch": 2.8230889235569423,
    "grad_norm": 2.7720468044281006,
    "learning_rate": 2.293144208037825e-05,
    "loss": 2.0276,
    "step": 4525
  },
  {
    "epoch": 2.8386895475819034,
    "grad_norm": 3.059398651123047,
    "learning_rate": 2.276727081691621e-05,
    "loss": 1.945,
    "step": 4550
  },
  {
    "epoch": 2.8542901716068645,
    "grad_norm": 3.4915013313293457,
    "learning_rate": 2.2603099553454165e-05,
    "loss": 1.8368,
    "step": 4575
  },
  {
    "epoch": 2.869890795631825,
    "grad_norm": 2.3720667362213135,
    "learning_rate": 2.243892828999212e-05,
    "loss": 1.8279,
    "step": 4600
  },
  {
    "epoch": 2.8854914196567862,
    "grad_norm": 2.5072028636932373,
    "learning_rate": 2.2274757026530076e-05,
    "loss": 1.8894,
    "step": 4625
  },
  {
    "epoch": 2.9010920436817473,
    "grad_norm": 3.244744300842285,
    "learning_rate": 2.2110585763068035e-05,
    "loss": 1.8138,
    "step": 4650
  },
  {
    "epoch": 2.9166926677067084,
    "grad_norm": 2.6711437702178955,
    "learning_rate": 2.194641449960599e-05,
    "loss": 1.9179,
    "step": 4675
  },
  {
    "epoch": 2.9322932917316695,
    "grad_norm": 2.4863967895507812,
    "learning_rate": 2.1782243236143947e-05,
    "loss": 1.8782,
    "step": 4700
  },
  {
    "epoch": 2.94789391575663,
    "grad_norm": 3.0056850910186768,
    "learning_rate": 2.1618071972681902e-05,
    "loss": 1.8695,
    "step": 4725
  },
  {
    "epoch": 2.9634945397815913,
    "grad_norm": 2.7103095054626465,
    "learning_rate": 2.1453900709219858e-05,
    "loss": 1.9609,
    "step": 4750
  },
  {
    "epoch": 2.9790951638065524,
    "grad_norm": 2.499060869216919,
    "learning_rate": 2.1289729445757817e-05,
    "loss": 1.7476,
    "step": 4775
  },
  {
    "epoch": 2.994695787831513,
    "grad_norm": 2.5959887504577637,
    "learning_rate": 2.112555818229577e-05,
    "loss": 1.8919,
    "step": 4800
  },
  {
    "epoch": 3.009984399375975,
    "grad_norm": 2.4627912044525146,
    "learning_rate": 2.096138691883373e-05,
    "loss": 1.789,
    "step": 4825
  },
  {
    "epoch": 3.025585023400936,
    "grad_norm": 2.6988167762756348,
    "learning_rate": 2.0797215655371684e-05,
    "loss": 1.9061,
    "step": 4850
  },
  {
    "epoch": 3.041185647425897,
    "grad_norm": 2.9557712078094482,
    "learning_rate": 2.0633044391909643e-05,
    "loss": 1.8833,
    "step": 4875
  },
  {
    "epoch": 3.056786271450858,
    "grad_norm": 2.3644394874572754,
    "learning_rate": 2.0468873128447596e-05,
    "loss": 1.7721,
    "step": 4900
  },
  {
    "epoch": 3.072386895475819,
    "grad_norm": 2.4955637454986572,
    "learning_rate": 2.0304701864985555e-05,
    "loss": 1.9156,
    "step": 4925
  },
  {
    "epoch": 3.08798751950078,
    "grad_norm": 2.5389232635498047,
    "learning_rate": 2.014053060152351e-05,
    "loss": 1.8288,
    "step": 4950
  },
  {
    "epoch": 3.103588143525741,
    "grad_norm": 2.4526939392089844,
    "learning_rate": 1.9976359338061466e-05,
    "loss": 1.819,
    "step": 4975
  },
  {
    "epoch": 3.119188767550702,
    "grad_norm": 2.523695707321167,
    "learning_rate": 1.9812188074599422e-05,
    "loss": 1.7436,
    "step": 5000
  },
  {
    "epoch": 3.119188767550702,
    "eval_loss": 2.0220773220062256,
    "eval_runtime": 30.4921,
    "eval_samples_per_second": 45.782,
    "eval_steps_per_second": 11.446,
    "step": 5000
  },
  {
    "epoch": 3.134789391575663,
    "grad_norm": 2.5995843410491943,
    "learning_rate": 1.9648016811137378e-05,
    "loss": 1.8182,
    "step": 5025
  },
  {
    "epoch": 3.150390015600624,
    "grad_norm": 2.675825595855713,
    "learning_rate": 1.9483845547675337e-05,
    "loss": 1.97,
    "step": 5050
  },
  {
    "epoch": 3.1659906396255852,
    "grad_norm": 2.7091572284698486,
    "learning_rate": 1.9319674284213292e-05,
    "loss": 1.758,
    "step": 5075
  },
  {
    "epoch": 3.181591263650546,
    "grad_norm": 2.9646570682525635,
    "learning_rate": 1.9155503020751248e-05,
    "loss": 1.7385,
    "step": 5100
  },
  {
    "epoch": 3.197191887675507,
    "grad_norm": 2.4734439849853516,
    "learning_rate": 1.8991331757289204e-05,
    "loss": 1.8277,
    "step": 5125
  },
  {
    "epoch": 3.212792511700468,
    "grad_norm": 2.565286159515381,
    "learning_rate": 1.8827160493827163e-05,
    "loss": 1.8985,
    "step": 5150
  },
  {
    "epoch": 3.228393135725429,
    "grad_norm": 2.5573558807373047,
    "learning_rate": 1.866298923036512e-05,
    "loss": 1.7248,
    "step": 5175
  },
  {
    "epoch": 3.24399375975039,
    "grad_norm": 2.672692060470581,
    "learning_rate": 1.8498817966903074e-05,
    "loss": 1.7729,
    "step": 5200
  },
  {
    "epoch": 3.259594383775351,
    "grad_norm": 2.854370355606079,
    "learning_rate": 1.833464670344103e-05,
    "loss": 1.7963,
    "step": 5225
  },
  {
    "epoch": 3.275195007800312,
    "grad_norm": 2.962430953979492,
    "learning_rate": 1.8170475439978986e-05,
    "loss": 1.8152,
    "step": 5250
  },
  {
    "epoch": 3.290795631825273,
    "grad_norm": 3.030959367752075,
    "learning_rate": 1.8006304176516945e-05,
    "loss": 1.6881,
    "step": 5275
  },
  {
    "epoch": 3.306396255850234,
    "grad_norm": 2.7105205059051514,
    "learning_rate": 1.7842132913054897e-05,
    "loss": 1.9178,
    "step": 5300
  },
  {
    "epoch": 3.321996879875195,
    "grad_norm": 2.7830774784088135,
    "learning_rate": 1.7677961649592856e-05,
    "loss": 1.6643,
    "step": 5325
  },
  {
    "epoch": 3.337597503900156,
    "grad_norm": 3.0812551975250244,
    "learning_rate": 1.7513790386130812e-05,
    "loss": 1.7636,
    "step": 5350
  },
  {
    "epoch": 3.353198127925117,
    "grad_norm": 2.648205041885376,
    "learning_rate": 1.734961912266877e-05,
    "loss": 1.8788,
    "step": 5375
  },
  {
    "epoch": 3.368798751950078,
    "grad_norm": 2.584965467453003,
    "learning_rate": 1.7185447859206723e-05,
    "loss": 1.8082,
    "step": 5400
  },
  {
    "epoch": 3.384399375975039,
    "grad_norm": 2.792036533355713,
    "learning_rate": 1.7021276595744682e-05,
    "loss": 1.7559,
    "step": 5425
  },
  {
    "epoch": 3.4,
    "grad_norm": 2.5133562088012695,
    "learning_rate": 1.6857105332282638e-05,
    "loss": 1.9021,
    "step": 5450
  },
  {
    "epoch": 3.415600624024961,
    "grad_norm": 2.712378978729248,
    "learning_rate": 1.6692934068820594e-05,
    "loss": 1.7141,
    "step": 5475
  },
  {
    "epoch": 3.431201248049922,
    "grad_norm": 2.3749635219573975,
    "learning_rate": 1.652876280535855e-05,
    "loss": 1.787,
    "step": 5500
  },
  {
    "epoch": 3.431201248049922,
    "eval_loss": 1.9947445392608643,
    "eval_runtime": 30.4097,
    "eval_samples_per_second": 45.906,
    "eval_steps_per_second": 11.477,
    "step": 5500
  },
  {
    "epoch": 3.446801872074883,
    "grad_norm": 2.800699472427368,
    "learning_rate": 1.6364591541896505e-05,
    "loss": 1.7098,
    "step": 5525
  },
  {
    "epoch": 3.462402496099844,
    "grad_norm": 3.2485239505767822,
    "learning_rate": 1.6200420278434464e-05,
    "loss": 1.7812,
    "step": 5550
  },
  {
    "epoch": 3.478003120124805,
    "grad_norm": 2.552863359451294,
    "learning_rate": 1.603624901497242e-05,
    "loss": 1.8764,
    "step": 5575
  },
  {
    "epoch": 3.493603744149766,
    "grad_norm": 2.895598888397217,
    "learning_rate": 1.5872077751510376e-05,
    "loss": 1.8141,
    "step": 5600
  },
  {
    "epoch": 3.509204368174727,
    "grad_norm": 2.559142827987671,
    "learning_rate": 1.570790648804833e-05,
    "loss": 1.742,
    "step": 5625
  },
  {
    "epoch": 3.5248049921996882,
    "grad_norm": 2.2334465980529785,
    "learning_rate": 1.554373522458629e-05,
    "loss": 1.7373,
    "step": 5650
  },
  {
    "epoch": 3.540405616224649,
    "grad_norm": 2.439180612564087,
    "learning_rate": 1.5379563961124246e-05,
    "loss": 1.7161,
    "step": 5675
  },
  {
    "epoch": 3.55600624024961,
    "grad_norm": 2.8374507427215576,
    "learning_rate": 1.52153926976622e-05,
    "loss": 1.857,
    "step": 5700
  },
  {
    "epoch": 3.571606864274571,
    "grad_norm": 2.2414984703063965,
    "learning_rate": 1.5051221434200158e-05,
    "loss": 1.7183,
    "step": 5725
  },
  {
    "epoch": 3.5872074882995317,
    "grad_norm": 2.834246873855591,
    "learning_rate": 1.4887050170738115e-05,
    "loss": 1.7194,
    "step": 5750
  },
  {
    "epoch": 3.602808112324493,
    "grad_norm": 2.6987764835357666,
    "learning_rate": 1.4722878907276073e-05,
    "loss": 1.7977,
    "step": 5775
  },
  {
    "epoch": 3.618408736349454,
    "grad_norm": 2.792827606201172,
    "learning_rate": 1.4558707643814027e-05,
    "loss": 1.8137,
    "step": 5800
  },
  {
    "epoch": 3.634009360374415,
    "grad_norm": 2.3365578651428223,
    "learning_rate": 1.4394536380351984e-05,
    "loss": 1.8199,
    "step": 5825
  },
  {
    "epoch": 3.649609984399376,
    "grad_norm": 2.5601961612701416,
    "learning_rate": 1.423036511688994e-05,
    "loss": 1.946,
    "step": 5850
  },
  {
    "epoch": 3.6652106084243368,
    "grad_norm": 2.9721457958221436,
    "learning_rate": 1.4066193853427897e-05,
    "loss": 1.7908,
    "step": 5875
  },
  {
    "epoch": 3.680811232449298,
    "grad_norm": 2.5831832885742188,
    "learning_rate": 1.3902022589965851e-05,
    "loss": 1.8621,
    "step": 5900
  },
  {
    "epoch": 3.696411856474259,
    "grad_norm": 2.722245454788208,
    "learning_rate": 1.3737851326503808e-05,
    "loss": 1.8191,
    "step": 5925
  },
  {
    "epoch": 3.71201248049922,
    "grad_norm": 2.547684907913208,
    "learning_rate": 1.3573680063041766e-05,
    "loss": 1.8093,
    "step": 5950
  },
  {
    "epoch": 3.727613104524181,
    "grad_norm": 2.551145076751709,
    "learning_rate": 1.3409508799579723e-05,
    "loss": 1.8466,
    "step": 5975
  },
  {
    "epoch": 3.743213728549142,
    "grad_norm": 2.510608196258545,
    "learning_rate": 1.3245337536117677e-05,
    "loss": 1.8513,
    "step": 6000
  },
  {
    "epoch": 3.743213728549142,
    "eval_loss": 1.9727146625518799,
    "eval_runtime": 30.4284,
    "eval_samples_per_second": 45.878,
    "eval_steps_per_second": 11.47,
    "step": 6000
  },
  {
    "loss": 1.7365,
    "grad_norm": 2.17509126663208,
    "learning_rate": 1.3081166272655635e-05,
    "epoch": 3.758814352574103,
    "step": 6025
  },
  {
    "loss": 1.6806,
    "grad_norm": 2.4700300693511963,
    "learning_rate": 1.2916995009193592e-05,
    "epoch": 3.774414976599064,
    "step": 6050
  },
  {
    "loss": 1.7331,
    "grad_norm": 2.779399871826172,
    "learning_rate": 1.2752823745731548e-05,
    "epoch": 3.790015600624025,
    "step": 6075
  },
  {
    "loss": 1.7551,
    "grad_norm": 2.2628278732299805,
    "learning_rate": 1.2588652482269504e-05,
    "epoch": 3.805616224648986,
    "step": 6100
  },
  {
    "loss": 1.6144,
    "grad_norm": 2.2884421348571777,
    "learning_rate": 1.242448121880746e-05,
    "epoch": 3.821216848673947,
    "step": 6125
  },
  {
    "loss": 1.8101,
    "grad_norm": 2.079988479614258,
    "learning_rate": 1.2260309955345417e-05,
    "epoch": 3.836817472698908,
    "step": 6150
  },
  {
    "loss": 1.7189,
    "grad_norm": 2.5797808170318604,
    "learning_rate": 1.2096138691883372e-05,
    "epoch": 3.852418096723869,
    "step": 6175
  },
  {
    "loss": 1.7176,
    "grad_norm": 2.724864959716797,
    "learning_rate": 1.193196742842133e-05,
    "epoch": 3.8680187207488297,
    "step": 6200
  },
  {
    "loss": 1.5842,
    "grad_norm": 2.5598294734954834,
    "learning_rate": 1.1767796164959285e-05,
    "epoch": 3.8836193447737912,
    "step": 6225
  },
  {
    "loss": 1.6435,
    "grad_norm": 2.5452446937561035,
    "learning_rate": 1.1603624901497243e-05,
    "epoch": 3.899219968798752,
    "step": 6250
  },
  {
    "loss": 1.8081,
    "grad_norm": 2.88930606842041,
    "learning_rate": 1.1439453638035199e-05,
    "epoch": 3.914820592823713,
    "step": 6275
  },
  {
    "loss": 1.7992,
    "grad_norm": 2.916750431060791,
    "learning_rate": 1.1275282374573156e-05,
    "epoch": 3.930421216848674,
    "step": 6300
  },
  {
    "loss": 1.7544,
    "grad_norm": 2.2611207962036133,
    "learning_rate": 1.1111111111111112e-05,
    "epoch": 3.9460218408736347,
    "step": 6325
  },
  {
    "loss": 1.6176,
    "grad_norm": 2.4471869468688965,
    "learning_rate": 1.0946939847649067e-05,
    "epoch": 3.961622464898596,
    "step": 6350
  },
  {
    "loss": 1.774,
    "grad_norm": 2.5561697483062744,
    "learning_rate": 1.0782768584187023e-05,
    "epoch": 3.977223088923557,
    "step": 6375
  },
  {
    "loss": 1.7783,
    "grad_norm": 2.709885597229004,
    "learning_rate": 1.061859732072498e-05,
    "epoch": 3.992823712948518,
    "step": 6400
  },
  {
    "loss": 1.8296,
    "grad_norm": 2.4176485538482666,
    "learning_rate": 1.0454426057262936e-05,
    "epoch": 4.0087363494539785,
    "step": 6425
  },
  {
    "loss": 1.7295,
    "grad_norm": 2.54990553855896,
    "learning_rate": 1.0290254793800894e-05,
    "epoch": 4.024336973478939,
    "step": 6450
  },
  {
    "loss": 1.7163,
    "grad_norm": 2.4511196613311768,
    "learning_rate": 1.012608353033885e-05,
    "epoch": 4.0399375975039,
    "step": 6475
  },
  {
    "loss": 1.7164,
    "grad_norm": 2.881309986114502,
    "learning_rate": 9.961912266876807e-06,
    "epoch": 4.055538221528861,
    "step": 6500
  },
  {
    "eval_loss": 1.9654630422592163,
    "eval_runtime": 30.8512,
    "eval_samples_per_second": 45.249,
    "eval_steps_per_second": 11.312,
    "epoch": 4.055538221528861,
    "step": 6500
  },
  {
    "loss": 1.779,
    "grad_norm": 2.7032251358032227,
    "learning_rate": 9.797741003414762e-06,
    "epoch": 4.071138845553822,
    "step": 6525
  },
  {
    "loss": 1.8082,
    "grad_norm": 2.523355484008789,
    "learning_rate": 9.63356973995272e-06,
    "epoch": 4.0867394695787835,
    "step": 6550
  },
  {
    "loss": 1.8265,
    "grad_norm": 3.072916269302368,
    "learning_rate": 9.469398476490675e-06,
    "epoch": 4.102340093603744,
    "step": 6575
  },
  {
    "loss": 1.7366,
    "grad_norm": 2.6368629932403564,
    "learning_rate": 9.305227213028631e-06,
    "epoch": 4.117940717628705,
    "step": 6600
  },
  {
    "loss": 1.8867,
    "grad_norm": 2.765284538269043,
    "learning_rate": 9.141055949566587e-06,
    "epoch": 4.133541341653666,
    "step": 6625
  },
  {
    "loss": 1.7201,
    "grad_norm": 2.833052158355713,
    "learning_rate": 8.976884686104544e-06,
    "epoch": 4.149141965678627,
    "step": 6650
  },
  {
    "loss": 1.7567,
    "grad_norm": 2.494572639465332,
    "learning_rate": 8.812713422642502e-06,
    "epoch": 4.164742589703589,
    "step": 6675
  },
  {
    "loss": 1.684,
    "grad_norm": 2.796339750289917,
    "learning_rate": 8.648542159180457e-06,
    "epoch": 4.180343213728549,
    "step": 6700
  },
  {
    "loss": 1.7734,
    "grad_norm": 3.5009567737579346,
    "learning_rate": 8.484370895718415e-06,
    "epoch": 4.19594383775351,
    "step": 6725
  },
  {
    "loss": 1.8474,
    "grad_norm": 2.8702445030212402,
    "learning_rate": 8.32019963225637e-06,
    "epoch": 4.211544461778471,
    "step": 6750
  },
  {
    "loss": 1.65,
    "grad_norm": 2.5715675354003906,
    "learning_rate": 8.156028368794328e-06,
    "epoch": 4.227145085803432,
    "step": 6775
  },
  {
    "loss": 1.6936,
    "grad_norm": 2.5269598960876465,
    "learning_rate": 7.991857105332284e-06,
    "epoch": 4.242745709828393,
    "step": 6800
  },
  {
    "loss": 1.814,
    "grad_norm": 2.779559373855591,
    "learning_rate": 7.82768584187024e-06,
    "epoch": 4.258346333853354,
    "step": 6825
  },
  {
    "loss": 1.7697,
    "grad_norm": 2.583770751953125,
    "learning_rate": 7.663514578408195e-06,
    "epoch": 4.273946957878315,
    "step": 6850
  },
  {
    "loss": 1.7341,
    "grad_norm": 2.25642991065979,
    "learning_rate": 7.4993433149461525e-06,
    "epoch": 4.2895475819032765,
    "step": 6875
  },
  {
    "loss": 1.9379,
    "grad_norm": 2.7854559421539307,
    "learning_rate": 7.335172051484108e-06,
    "epoch": 4.305148205928237,
    "step": 6900
  },
  {
    "loss": 1.6442,
    "grad_norm": 2.542259454727173,
    "learning_rate": 7.1710007880220656e-06,
    "epoch": 4.320748829953198,
    "step": 6925
  },
  {
    "loss": 1.8205,
    "grad_norm": 2.122695207595825,
    "learning_rate": 7.006829524560021e-06,
    "epoch": 4.336349453978159,
    "step": 6950
  },
  {
    "loss": 1.6797,
    "grad_norm": 3.0201644897460938,
    "learning_rate": 6.842658261097979e-06,
    "epoch": 4.35195007800312,
    "step": 6975
  },
  {
    "loss": 1.7984,
    "grad_norm": 2.7436671257019043,
    "learning_rate": 6.678486997635934e-06,
    "epoch": 4.3675507020280815,
    "step": 7000
  },
  {
    "eval_loss": 1.952600359916687,
    "eval_runtime": 30.8577,
    "eval_samples_per_second": 45.24,
    "eval_steps_per_second": 11.31,
    "epoch": 4.3675507020280815,
    "step": 7000
  },
  {
    "loss": 1.7206,
    "grad_norm": 2.877882242202759,
    "learning_rate": 6.514315734173891e-06,
    "epoch": 4.383151326053042,
    "step": 7025
  },
  {
    "loss": 1.6819,
    "grad_norm": 2.1562933921813965,
    "learning_rate": 6.350144470711847e-06,
    "epoch": 4.398751950078003,
    "step": 7050
  },
  {
    "loss": 1.8046,
    "grad_norm": 2.2997817993164062,
    "learning_rate": 6.185973207249803e-06,
    "epoch": 4.414352574102964,
    "step": 7075
  },
  {
    "loss": 1.844,
    "grad_norm": 2.4687578678131104,
    "learning_rate": 6.02180194378776e-06,
    "epoch": 4.429953198127925,
    "step": 7100
  },
  {
    "loss": 1.8241,
    "grad_norm": 2.510476589202881,
    "learning_rate": 5.857630680325716e-06,
    "epoch": 4.4455538221528865,
    "step": 7125
  },
  {
    "loss": 1.8114,
    "grad_norm": 2.687762975692749,
    "learning_rate": 5.693459416863672e-06,
    "epoch": 4.461154446177847,
    "step": 7150
  },
  {
    "loss": 1.8015,
    "grad_norm": 2.3122718334198,
    "learning_rate": 5.5292881534016286e-06,
    "epoch": 4.476755070202808,
    "step": 7175
  },
  {
    "loss": 1.6071,
    "grad_norm": 2.391265630722046,
    "learning_rate": 5.365116889939585e-06,
    "epoch": 4.492355694227769,
    "step": 7200
  },
  {
    "loss": 1.7546,
    "grad_norm": 2.546635150909424,
    "learning_rate": 5.200945626477542e-06,
    "epoch": 4.50795631825273,
    "step": 7225
  },
  {
    "loss": 1.6667,
    "grad_norm": 2.6545143127441406,
    "learning_rate": 5.036774363015498e-06,
    "epoch": 4.523556942277692,
    "step": 7250
  },
  {
    "loss": 1.7431,
    "grad_norm": 2.913821220397949,
    "learning_rate": 4.872603099553454e-06,
    "epoch": 4.539157566302652,
    "step": 7275
  },
  {
    "loss": 1.7273,
    "grad_norm": 2.623300075531006,
    "learning_rate": 4.7084318360914105e-06,
    "epoch": 4.554758190327613,
    "step": 7300
  },
  {
    "loss": 1.6123,
    "grad_norm": 2.5338869094848633,
    "learning_rate": 4.544260572629367e-06,
    "epoch": 4.570358814352574,
    "step": 7325
  },
  {
    "loss": 1.707,
    "grad_norm": 2.7202084064483643,
    "learning_rate": 4.380089309167324e-06,
    "epoch": 4.585959438377535,
    "step": 7350
  },
  {
    "loss": 1.7487,
    "grad_norm": 2.6320621967315674,
    "learning_rate": 4.21591804570528e-06,
    "epoch": 4.601560062402497,
    "step": 7375
  },
  {
    "loss": 1.479,
    "grad_norm": 2.4618940353393555,
    "learning_rate": 4.051746782243236e-06,
    "epoch": 4.617160686427457,
    "step": 7400
  },
  {
    "loss": 1.7614,
    "grad_norm": 2.5630016326904297,
    "learning_rate": 3.887575518781192e-06,
    "epoch": 4.632761310452418,
    "step": 7425
  },
  {
    "loss": 1.5316,
    "grad_norm": 2.49643611907959,
    "learning_rate": 3.723404255319149e-06,
    "epoch": 4.648361934477379,
    "step": 7450
  },
  {
    "loss": 1.697,
    "grad_norm": 2.8938231468200684,
    "learning_rate": 3.5592329918571055e-06,
    "epoch": 4.66396255850234,
    "step": 7475
  },
  {
    "loss": 1.7271,
    "grad_norm": 2.563906669616699,
    "learning_rate": 3.3950617283950617e-06,
    "epoch": 4.679563182527301,
    "step": 7500
  },
  {
    "eval_loss": 1.9476685523986816,
    "eval_runtime": 30.7335,
    "eval_samples_per_second": 45.423,
    "eval_steps_per_second": 11.356,
    "epoch": 4.679563182527301,
    "step": 7500
  },
  {
    "loss": 1.5864,
    "grad_norm": 2.650864601135254,
    "learning_rate": 3.230890464933018e-06,
    "epoch": 4.695163806552262,
    "step": 7525
  },
  {
    "loss": 1.7676,
    "grad_norm": 2.819607973098755,
    "learning_rate": 3.0667192014709748e-06,
    "epoch": 4.710764430577223,
    "step": 7550
  },
  {
    "loss": 1.7068,
    "grad_norm": 2.3071489334106445,
    "learning_rate": 2.9025479380089313e-06,
    "epoch": 4.726365054602184,
    "step": 7575
  },
  {
    "loss": 1.7801,
    "grad_norm": 2.5078563690185547,
    "learning_rate": 2.7383766745468875e-06,
    "epoch": 4.741965678627145,
    "step": 7600
  },
  {
    "loss": 1.8123,
    "grad_norm": 2.5449185371398926,
    "learning_rate": 2.574205411084844e-06,
    "epoch": 4.757566302652106,
    "step": 7625
  },
  {
    "loss": 1.587,
    "grad_norm": 2.161797523498535,
    "learning_rate": 2.4100341476228e-06,
    "epoch": 4.773166926677067,
    "step": 7650
  },
  {
    "loss": 1.5959,
    "grad_norm": 2.8901164531707764,
    "learning_rate": 2.2458628841607567e-06,
    "epoch": 4.788767550702028,
    "step": 7675
  },
  {
    "loss": 1.6227,
    "grad_norm": 2.635308265686035,
    "learning_rate": 2.0816916206987132e-06,
    "epoch": 4.804368174726989,
    "step": 7700
  },
  {
    "loss": 1.6615,
    "grad_norm": 2.9234044551849365,
    "learning_rate": 1.9175203572366694e-06,
    "epoch": 4.81996879875195,
    "step": 7725
  },
  {
    "loss": 1.6448,
    "grad_norm": 2.6054201126098633,
    "learning_rate": 1.753349093774626e-06,
    "epoch": 4.835569422776911,
    "step": 7750
  },
  {
    "loss": 1.6912,
    "grad_norm": 2.3281772136688232,
    "learning_rate": 1.5891778303125823e-06,
    "epoch": 4.851170046801872,
    "step": 7775
  },
  {
    "loss": 1.4614,
    "grad_norm": 2.153475522994995,
    "learning_rate": 1.4250065668505384e-06,
    "epoch": 4.866770670826833,
    "step": 7800
  },
  {
    "loss": 1.7364,
    "grad_norm": 2.7296321392059326,
    "learning_rate": 1.260835303388495e-06,
    "epoch": 4.882371294851794,
    "step": 7825
  },
  {
    "loss": 1.6998,
    "grad_norm": 2.1688663959503174,
    "learning_rate": 1.0966640399264513e-06,
    "epoch": 4.897971918876755,
    "step": 7850
  },
  {
    "loss": 1.6635,
    "grad_norm": 2.2821176052093506,
    "learning_rate": 9.324927764644077e-07,
    "epoch": 4.913572542901716,
    "step": 7875
  },
  {
    "loss": 1.5796,
    "grad_norm": 2.3923752307891846,
    "learning_rate": 7.683215130023641e-07,
    "epoch": 4.929173166926677,
    "step": 7900
  },
  {
    "loss": 1.6717,
    "grad_norm": 2.1402621269226074,
    "learning_rate": 6.041502495403204e-07,
    "epoch": 4.944773790951638,
    "step": 7925
  },
  {
    "loss": 1.6601,
    "grad_norm": 2.649266242980957,
    "learning_rate": 4.3997898607827683e-07,
    "epoch": 4.960374414976599,
    "step": 7950
  },
  {
    "loss": 1.724,
    "grad_norm": 2.592003107070923,
    "learning_rate": 2.758077226162333e-07,
    "epoch": 4.97597503900156,
    "step": 7975
  },
  {
    "loss": 1.6806,
    "grad_norm": 2.309621810913086,
    "learning_rate": 1.1163645915418966e-07,
    "epoch": 4.991575663026521,
    "step": 8000
  },
  {
    "eval_loss": 1.9423450231552124,
    "eval_runtime": 30.7414,
    "eval_samples_per_second": 45.411,
    "eval_steps_per_second": 11.353,
    "epoch": 4.991575663026521,
    "step": 8000
  },
  {
    "train_runtime": 1478.2865,
    "train_samples_per_second": 43.361,
    "train_steps_per_second": 5.422,
    "total_flos": 1.4917260126879744e+16,
    "train_loss": 0.4316215184313834,
    "epoch": 5.0,
    "step": 8014
  },
  {
    "eval_loss": 1.9423476457595825,
    "eval_runtime": 30.7662,
    "eval_samples_per_second": 45.374,
    "eval_steps_per_second": 11.344,
    "epoch": 5.0,
    "step": 8014
  }
]