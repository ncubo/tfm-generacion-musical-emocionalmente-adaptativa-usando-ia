{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45dcfb15",
   "metadata": {},
   "source": [
    "# Fine-tuning Maestro-REMI con Condicionamiento VA (Run Limpio)\n",
    "\n",
    "**Objetivo**: Entrenamiento completo desde cero para obtener logs completos y métricas limpias.  \n",
    "**Resistente a desconexiones**: Checkpoints se guardan en Google Drive y el runtime se acumula entre sesiones.\n",
    "\n",
    "**Modelo base**: `Natooz/Maestro-REMI-bpe20k`  \n",
    "**Dataset**: Lakh Piano subset con etiquetas VA heurísticas  \n",
    "**Output en Drive**: `TFM/finetune_checkpoints/` + `training_log_history.json`\n",
    "\n",
    "### Instrucciones si Colab se desconecta:\n",
    "1. Reconectar y ejecutar Celdas 1, 2, 3 (montar, copiar, instalar)\n",
    "2. Ejecutar Celda 4 → **auto-detecta checkpoint y reanuda** (el runtime total se acumula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8990d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Copiar y descomprimir finetune_bundle\n",
    "%cd /content\n",
    "!cp \"/content/drive/MyDrive/TFM/finetune_bundle.tar.gz\" .\n",
    "!tar -xzf finetune_bundle.tar.gz\n",
    "%cd /content/finetune_bundle\n",
    "!ls -la\n",
    "!ls -la data/finetune_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: Instalar dependencias\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e74e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: Fine-tuning con checkpoints en Drive (resistente a desconexiones)\n",
    "# - output_dir apunta a Drive → checkpoints persisten si Colab se cae\n",
    "# - Auto-detecta checkpoint previo y reanuda automáticamente\n",
    "# - Runtime se acumula entre sesiones en cumulative_runtime.json\n",
    "# - save_steps=1500 (~1 por época) para evitar freezes por I/O a Drive\n",
    "import subprocess, os, sys\n",
    "\n",
    "DRIVE_CKPT = \"/content/drive/MyDrive/TFM/finetune_checkpoints\"\n",
    "os.makedirs(DRIVE_CKPT, exist_ok=True)\n",
    "\n",
    "# Construir comando\n",
    "cmd = [\n",
    "    sys.executable, \"train_maestro_finetune.py\",\n",
    "    \"--model_name\", \"Natooz/Maestro-REMI-bpe20k\",\n",
    "    \"--dataset_dir\", \"data/finetune_dataset\",\n",
    "    \"--output_dir\", DRIVE_CKPT,\n",
    "    \"--num_train_epochs\", \"5\",\n",
    "    \"--per_device_train_batch_size\", \"4\",\n",
    "    \"--per_device_eval_batch_size\", \"4\",\n",
    "    \"--gradient_accumulation_steps\", \"2\",\n",
    "    \"--learning_rate\", \"5e-5\",\n",
    "    \"--warmup_ratio\", \"0.05\",\n",
    "    \"--logging_steps\", \"25\",\n",
    "    \"--eval_steps\", \"500\",\n",
    "    \"--save_steps\", \"1500\",\n",
    "    \"--save_total_limit\", \"2\",\n",
    "    \"--fp16\",\n",
    "    \"--gradient_checkpointing\",\n",
    "    \"--seed\", \"42\",\n",
    "]\n",
    "\n",
    "# Auto-detectar checkpoint previo para reanudar\n",
    "checkpoints = sorted([\n",
    "    d for d in os.listdir(DRIVE_CKPT)\n",
    "    if d.startswith(\"checkpoint-\")\n",
    "]) if os.path.exists(DRIVE_CKPT) else []\n",
    "\n",
    "if checkpoints:\n",
    "    last_ckpt = os.path.join(DRIVE_CKPT, checkpoints[-1])\n",
    "    cmd += [\"--resume_from_checkpoint\", last_ckpt]\n",
    "    # Mostrar runtime acumulado previo\n",
    "    rt_path = os.path.join(DRIVE_CKPT, \"cumulative_runtime.json\")\n",
    "    prev_min = 0\n",
    "    if os.path.exists(rt_path):\n",
    "        import json\n",
    "        with open(rt_path) as f:\n",
    "            prev_min = json.load(f).get(\"total_runtime_sec\", 0) / 60\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"REANUDANDO desde: {checkpoints[-1]}\")\n",
    "    print(f\"Runtime acumulado previo: {prev_min:.1f} min\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "else:\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"INICIANDO entrenamiento DESDE CERO\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Ejecutar con output en tiempo real\n",
    "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "for line in process.stdout:\n",
    "    print(line, end=\"\")\n",
    "process.wait()\n",
    "\n",
    "if process.returncode != 0:\n",
    "    print(f\"\\nERROR: Proceso terminó con código {process.returncode}\")\n",
    "else:\n",
    "    print(f\"\\nEntrenamiento completado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f12e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: Exportar modelo final desde checkpoints de Drive\n",
    "import shutil, os, json\n",
    "\n",
    "DRIVE_CKPT = \"/content/drive/MyDrive/TFM/finetune_checkpoints\"\n",
    "export_dir = \"/content/drive/MyDrive/TFM/finetune_results_clean\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# Copiar modelo final\n",
    "final_dir = os.path.join(DRIVE_CKPT, \"final\")\n",
    "if os.path.exists(final_dir):\n",
    "    shutil.copytree(final_dir, os.path.join(export_dir, \"final\"), dirs_exist_ok=True)\n",
    "    print(f\"Modelo final copiado a {export_dir}/final\")\n",
    "else:\n",
    "    # Usar el último checkpoint como fallback\n",
    "    checkpoints = sorted([d for d in os.listdir(DRIVE_CKPT) if d.startswith(\"checkpoint-\")])\n",
    "    if checkpoints:\n",
    "        last = os.path.join(DRIVE_CKPT, checkpoints[-1])\n",
    "        shutil.copytree(last, os.path.join(export_dir, \"final\"), dirs_exist_ok=True)\n",
    "        print(f\"Último checkpoint ({checkpoints[-1]}) copiado como modelo final\")\n",
    "\n",
    "# Copiar logs de entrenamiento\n",
    "for fname in [\"training_summary.json\", \"training_log_history.json\", \"cumulative_runtime.json\"]:\n",
    "    for search_dir in [DRIVE_CKPT, final_dir if os.path.exists(final_dir) else \"\"]:\n",
    "        src = os.path.join(search_dir, fname) if search_dir else \"\"\n",
    "        if src and os.path.exists(src):\n",
    "            shutil.copy2(src, export_dir)\n",
    "            print(f\"{fname} copiado\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"{fname} no encontrado\")\n",
    "\n",
    "print(f\"\\nArchivos exportados en {export_dir}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08dc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6: Verificación de resultados\n",
    "import json, os\n",
    "\n",
    "DRIVE_CKPT = \"/content/drive/MyDrive/TFM/finetune_checkpoints\"\n",
    "\n",
    "# Training Summary\n",
    "for d in [DRIVE_CKPT, os.path.join(DRIVE_CKPT, \"final\")]:\n",
    "    sp = os.path.join(d, \"training_summary.json\")\n",
    "    if os.path.exists(sp):\n",
    "        with open(sp) as f:\n",
    "            summary = json.load(f)\n",
    "        print(\"=\" * 60)\n",
    "        print(\"RESUMEN DEL ENTRENAMIENTO\")\n",
    "        print(\"=\" * 60)\n",
    "        for k, v in summary.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"training_summary.json no encontrado\")\n",
    "\n",
    "# Runtime acumulado\n",
    "rt_path = os.path.join(DRIVE_CKPT, \"cumulative_runtime.json\")\n",
    "if os.path.exists(rt_path):\n",
    "    with open(rt_path) as f:\n",
    "        rt = json.load(f)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"RUNTIME ACUMULADO\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Total: {rt.get('total_runtime_sec',0)/60:.2f} min ({rt.get('total_runtime_sec',0)/3600:.2f} h)\")\n",
    "    print(f\"  Última sesión: {rt.get('session_runtime_sec',0)/60:.2f} min\")\n",
    "    print(f\"  Sesiones previas: {rt.get('previous_runtime_sec',0)/60:.2f} min\")\n",
    "\n",
    "# Log history\n",
    "for d in [DRIVE_CKPT, os.path.join(DRIVE_CKPT, \"final\")]:\n",
    "    lp = os.path.join(d, \"training_log_history.json\")\n",
    "    if os.path.exists(lp):\n",
    "        with open(lp) as f:\n",
    "            logs = json.load(f)\n",
    "        train_entries = [e for e in logs if 'loss' in e and 'eval_loss' not in e]\n",
    "        eval_entries = [e for e in logs if 'eval_loss' in e]\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"LOG HISTORY: {len(logs)} entradas\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"  Train loss entries: {len(train_entries)}\")\n",
    "        print(f\"  Eval loss entries: {len(eval_entries)}\")\n",
    "        if train_entries:\n",
    "            print(f\"  Steps: {train_entries[0].get('step','?')} -> {train_entries[-1].get('step','?')}\")\n",
    "            print(f\"  Loss: {train_entries[0].get('loss','?')} -> {train_entries[-1].get('loss','?')}\")\n",
    "        if eval_entries:\n",
    "            print(f\"  Eval loss: {eval_entries[0].get('eval_loss','?')} -> {eval_entries[-1].get('eval_loss','?')}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"training_log_history.json no encontrado\")\n",
    "\n",
    "# Checkpoints en Drive\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CHECKPOINTS EN DRIVE\")\n",
    "print(\"=\" * 60)\n",
    "if os.path.exists(DRIVE_CKPT):\n",
    "    for item in sorted(os.listdir(DRIVE_CKPT)):\n",
    "        full = os.path.join(DRIVE_CKPT, item)\n",
    "        if os.path.isdir(full):\n",
    "            n_files = len(os.listdir(full))\n",
    "            print(f\"  [dir] {item} ({n_files} archivos)\")\n",
    "        else:\n",
    "            size = os.path.getsize(full) / 1e6\n",
    "            print(f\"  [file] {item} ({size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c406014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7: Verificar entorno de trabajo (GPU, RAM, disco)\n",
    "import subprocess, os, psutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ENTORNO DE EJECUCIÓN - GOOGLE COLAB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# GPU\n",
    "print(\"\\n--- GPU ---\")\n",
    "try:\n",
    "    gpu_info = subprocess.check_output([\"nvidia-smi\"], text=True)\n",
    "    print(gpu_info)\n",
    "except Exception:\n",
    "    print(\"No se detectó GPU (usando CPU)\")\n",
    "\n",
    "# GPU con PyTorch\n",
    "print(\"--- PyTorch GPU ---\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"  CUDA disponible: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  Dispositivo: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  VRAM total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"  VRAM reservada: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "        print(f\"  VRAM asignada: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "        print(f\"  Compute capability: {torch.cuda.get_device_properties(0).major}.{torch.cuda.get_device_properties(0).minor}\")\n",
    "    print(f\"  PyTorch version: {torch.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"  PyTorch no instalado aún\")\n",
    "\n",
    "# RAM\n",
    "print(\"\\n--- RAM ---\")\n",
    "ram = psutil.virtual_memory()\n",
    "print(f\"  Total: {ram.total / 1e9:.2f} GB\")\n",
    "print(f\"  Disponible: {ram.available / 1e9:.2f} GB\")\n",
    "print(f\"  Usada: {ram.used / 1e9:.2f} GB ({ram.percent}%)\")\n",
    "\n",
    "# CPU\n",
    "print(\"\\n--- CPU ---\")\n",
    "print(f\"  Cores físicos: {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"  Cores lógicos: {psutil.cpu_count(logical=True)}\")\n",
    "try:\n",
    "    cpu_model = subprocess.check_output([\"cat\", \"/proc/cpuinfo\"], text=True)\n",
    "    for line in cpu_model.split(\"\\n\"):\n",
    "        if \"model name\" in line:\n",
    "            print(f\"  Modelo: {line.split(':')[1].strip()}\")\n",
    "            break\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Disco\n",
    "print(\"\\n--- Disco ---\")\n",
    "disk = psutil.disk_usage(\"/content\" if os.path.exists(\"/content\") else \"/\")\n",
    "print(f\"  Total: {disk.total / 1e9:.2f} GB\")\n",
    "print(f\"  Usado: {disk.used / 1e9:.2f} GB\")\n",
    "print(f\"  Libre: {disk.free / 1e9:.2f} GB ({100 - disk.percent:.1f}%)\")\n",
    "\n",
    "# Tipo de runtime\n",
    "print(\"\\n--- Runtime Colab ---\")\n",
    "try:\n",
    "    if os.path.exists(\"/proc/driver/nvidia/version\"):\n",
    "        with open(\"/proc/driver/nvidia/version\") as f:\n",
    "            print(f\"  Driver NVIDIA: {f.readline().strip()}\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Detectar si es Colab Pro\n",
    "print(f\"  RAM total: {'> 12 GB (Pro/Pro+)' if ram.total > 13e9 else '<= 12 GB (Free)'}\")\n",
    "if torch.cuda.is_available():\n",
    "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    if \"A100\" in gpu_name:\n",
    "        print(f\"  GPU: {gpu_name} - Colab Pro+ tier\")\n",
    "    elif \"V100\" in gpu_name or vram_gb > 15:\n",
    "        print(f\"  GPU: {gpu_name} ({vram_gb:.0f} GB) - Colab Pro tier\")\n",
    "    else:\n",
    "        print(f\"  GPU: {gpu_name} ({vram_gb:.0f} GB) - Free/Pro tier\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
